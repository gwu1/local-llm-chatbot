{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A demo chatbot for return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import time\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume information in the return policy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define what documents to load\n",
    "# in the demo here, we have 4 textfiles that store the return policy namely \"return1_en.txt\", \"return2_en.txt\", \"return3_en.txt\", \"return4_en.txt\"\n",
    "loader = DirectoryLoader(\"./\", glob=\"*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "# interpret information in the documents\n",
    "documents = loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "texts = splitter.split_documents(documents)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'})\n",
    "\n",
    "# create and save the local vector database\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "db.save_local(\"faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a LLM that knows about our return policy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the template we will use when prompting the AI\n",
    "template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "# load the language model\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "config = {'max_new_tokens': 2048, 'context_length': 4096, 'temperature': 0.01}\n",
    "llm = CTransformers(model='llama-2-7b-chat.ggmlv3.q8_0.bin',\n",
    "                    model_type='llama', config=config)\n",
    "\n",
    "# load the interpreted information from the local database\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={'device': 'cpu'})\n",
    "db = FAISS.load_local(\"faiss\", embeddings)\n",
    "\n",
    "# prepare a version of the llm pre-loaded with the local content\n",
    "retriever = db.as_retriever(search_kwargs={'k': 2})\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['context', 'question'])\n",
    "\n",
    "QA_LLM = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                     chain_type='stuff',\n",
    "                                     retriever=retriever,\n",
    "                                     return_source_documents=True,\n",
    "                                     chain_type_kwargs={'prompt': prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(model, question):\n",
    "    model_path = model.combine_documents_chain.llm_chain.llm.model\n",
    "    model_name = pathlib.Path(model_path).name\n",
    "    time_start = time.time()\n",
    "    output = model.invoke({'query': question})\n",
    "    response = output[\"result\"]\n",
    "    time_elapsed = time.time() - time_start\n",
    "    display(HTML(f'<strong>Question:</strong> {question}'))\n",
    "    display(HTML(f'<strong>Answer:</strong> {response}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Question:</strong> i want to return a ring"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Answer:</strong> You can follow the steps outlined in section 1 of the user agreement to return your ring. Please make sure to include all original packaging, certificates, and receipts when shipping the ring back to us."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(QA_LLM, \"i want to return a ring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Question:</strong> within 5 days?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Answer:</strong> You can return an item within 7 days of delivery for a full refund, excluding initial shipping costs and tax and duties."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(QA_LLM, \"within 5 days?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>Question:</strong> money back?"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Answer:</strong> You can request for a refund of the amount you paid for the item, excluding initial shipping costs and tax and duties, within 7 days of delivery. Please follow the instructions provided in the Return Policy to initiate the return process."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query(QA_LLM, \"money back?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
